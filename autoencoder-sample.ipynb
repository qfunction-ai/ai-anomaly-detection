{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cc7aa2-7b2f-43e7-b1b9-b1fbda4ae2a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sumologic import SumoLogic\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e290808-67aa-4b01-addb-0e6ff13bfd57",
   "metadata": {},
   "source": [
    "# 1. Establish Your Use Case\n",
    "The first step of any QFuncion engagement is determining the cybersecurity use case to which you would like to apply AI. Most clients will perform one or more of the following:\n",
    "\n",
    "* Monitor some high priority or high value system(s) for anomalous logs activity\n",
    "* Perform a single threat hunt on some user, system, network, or appliance\n",
    "* Implement User Entity Behavior Analytics (UEBA) in the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f91ca4-b3d3-47b7-a89f-713d79427122",
   "metadata": {},
   "source": [
    "# 2. Collect Data\n",
    "Depending on your use case, we will need to collect the appropriate data. This example notebook shows how AI can be used to monitor anomalies and threats that occur on the command line of a Windows domain controller. The Windows domain controller has been configured to log event code 4688 with command line logging enabled. The logs have been collected into SumoLogic and have been retrieved in CSV form.\n",
    "\n",
    "Generally speaking, the more logs available, the better the AI will perform. QFunction suggests collecting 3-6 months of data minimum to establish a proper baseline of what's \"normal\" for your users, systems, or networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195655b-1dee-41de-b56d-e19677c86268",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('all-sumologic-results-november2023-tripled.csv', 'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "data = {'domain_name': [], 'username':[], 'command_line':[], 'parent_process_name':[]}\n",
    "\n",
    "for line in lines:\n",
    "    message_fields = line.split(',')\n",
    "    data['domain_name'].append(message_fields[2].strip())\n",
    "    data['username'].append(message_fields[3].strip())\n",
    "    data['command_line'].append(message_fields[0].strip())\n",
    "    data['parent_process_name'].append(message_fields[1].strip())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d296c0-6ae5-4351-b7bd-370416ef7a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7a37b5-a29b-456c-9e7a-2c61adcfd1b8",
   "metadata": {},
   "source": [
    "# 3. Create and Train the AI Model\n",
    "\n",
    "This AI is used to establish the \"normal\" for your collected data and is customized for whatever your use case may be.\n",
    "\n",
    "Training the AI can take a number of days depending on the amount of data the AI is given. Because every client has their own data security regulations, it is up to the discretion of the client as to where the model is trained. The common options are as follows:\n",
    "\n",
    "* Dedicated Cloud Server with GPU support (best option, yet expensive)\n",
    "* Dedicated Cloud Server with enough CPU and RAM (not as fast, but still works, more cost effective)\n",
    "* On-Prem Server with enough CPU and RAM (same as dedicated cloud server, may be cheaper due to on-prem)\n",
    "* QFunction Cloud server (charges will be added to engagement cost)\n",
    "\n",
    "Keep in mind that systems with high resources are only used for training; the actual production setup will require less resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056bb920-dfc9-4961-9da8-d122f3e76331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_autoencoder_model(df):\n",
    "    lengths = np.array([len(line.replace('\\n','').replace('\\r','')) for line in df['domain_name']+' '+df['username']+' '+df['command_line']+' '+df['parent_process_name']])\n",
    "    max_length = int(lengths.mean() + lengths.std())\n",
    "    print(max_length)\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(256, 4, input_length=max_length))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='tanh'))\n",
    "    model.add(layers.Dense(64, activation='tanh'))\n",
    "    model.add(layers.Dense(32, activation='tanh'))\n",
    "    model.add(layers.Dense(16, activation='tanh'))\n",
    "    model.add(layers.Dense(32, activation='tanh'))\n",
    "    model.add(layers.Dense(64, activation='tanh'))\n",
    "    model.add(layers.Dense(128, activation='tanh'))\n",
    "    model.add(layers.Dense(max_length, activation='tanh'))\n",
    "    return model, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3479d9-ce7b-4f2f-907e-a80f7ebbcb72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(model,max_length):\n",
    "    x = [np.frombuffer(bytearray(line, 'utf-8'), np.uint8) for line in df['domain_name']+' '+df['username']+' '+df['command_line']+' '+df['parent_process_name']]\n",
    "    x = pad_sequences(x, maxlen=max_length, padding='post', value=0, truncating='post')\n",
    "    scaler = MinMaxScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "    x = x.astype(np.float32)\n",
    "    model.compile(loss='mae', optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.00001))\n",
    "    model.fit(x, x, epochs=20)\n",
    "    print(x.shape)\n",
    "    info = {\"message\": \"model trained\"}\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3748ce-d745-462a-8cd4-45426a05abc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, max_length = initialize_autoencoder_model(df)\n",
    "info = fit(model, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f28b364-7a0b-4201-a651-92737b766ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply(model, df, max_length):\n",
    "    x = [np.frombuffer(bytearray(line, 'utf-8'), np.uint8) for line in df['domain_name']+' '+df['username']+' '+df['command_line']+' '+df['parent_process_name']]\n",
    "    x = pad_sequences(x, maxlen=max_length, padding='post', value=0, truncating='post')\n",
    "    scaler = MinMaxScaler()\n",
    "    x = scaler.fit_transform(x)\n",
    "    x = x.astype(np.uint8)\n",
    "    reconstruction_scores = tf.keras.losses.mae(x, model.predict(x, verbose=False))\n",
    "    #y_hat = tf.keras.metrics.RootMeanSquaredError(x, model.predict(x, verbose=False))\n",
    "    #print(y_hat)\n",
    "    #print(type(y_hat))\n",
    "    result = pd.DataFrame(reconstruction_scores, columns=['reconstruction_loss'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1a2a1e-bb8d-4d4b-915e-77423d2560c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_predictions = apply(model, df, max_length)\n",
    "orig_predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c330f3-235b-42ee-ac9f-b8d5291e5380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_predictions.min()\n",
    "p_sorted = orig_predictions.sort_values(by='reconstruction_loss', ascending=False)\n",
    "print(p_sorted)\n",
    "\n",
    "r = []\n",
    "for i in list(p_sorted.index.values)[:100]:\n",
    "    print(df.iloc[i]['domain_name'] + ' ' + df.iloc[i]['username'] + ' ' + df.iloc[i]['command_line'] + ' ' + df.iloc[i]['parent_process_name'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f296b770-daf2-47ee-b176-d507fa7d40a8",
   "metadata": {},
   "source": [
    "# 4. Connecting to Your SIEM\n",
    "After the model is trained, it will be ready to process new, incoming logs to determine whether they are \"normal\" for your environment. These incoming logs originate from your SIEM. All SIEMs have APIs that can be used to collect new data programatically which will be given to the AI to determine anomalies.\n",
    "\n",
    "Below is an example usage of retrieving new logs via the SumoLogic API and feeding the logs to the AI to determine anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89fe625-f9b3-47cd-9aef-a45f5e937138",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_id = ''\n",
    "access_key = ''\n",
    "endpoint = 'https://api.sumologic.com/api'\n",
    "sumo = SumoLogic(access_id, access_key, endpoint)\n",
    "time_zone = \"PST\"\n",
    "by_receipt_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc1e5e-397a-418c-8cde-b53d84a630d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '_collector=\"WIN-HDJETKALNBL\" | json auto | where event_id.id = 4688 | fields event_data.SubjectDomainName, event_data.SubjectUserName, event_data.CommandLine, event_data.ParentProcessName'\n",
    "to_time = int(time.time() * 1000)\n",
    "#from_time = to_time - (60000 * 30) #Subtract 30 minutes\n",
    "from_time = to_time - 86400000  #Subtract 1 day\n",
    "#from_time = to_time - 86400000 * 3  #Subtract 2 days\n",
    "#from_time = to_time - (86400000 * 28)  #Subtract 2 days\n",
    "sj = sumo.search_job(query, from_time, to_time, time_zone, by_receipt_time)\n",
    "\n",
    "status = sumo.search_job_status(sj)\n",
    "delay = 5\n",
    "while status['state'] != 'DONE GATHERING RESULTS':\n",
    "    if status['state'] == 'CANCELLED':\n",
    "        break\n",
    "    time.sleep(delay)\n",
    "    status = sumo.search_job_status(sj)\n",
    "    \n",
    "count = int(status['messageCount'])\n",
    "print(\"Number of results: \" + str(count))\n",
    "limit = count if count != 0 else 0\n",
    "r = sumo.search_job_messages(sj, limit=limit)\n",
    "\n",
    "test_df = {'domain_name': [], 'username':[], 'command_line':[], 'parent_process_name':[]}\n",
    "test_data = []\n",
    "\n",
    "for message in r['messages']:\n",
    "    dn = message['map']['event_data.subjectdomainname'].strip().replace('\"','')\n",
    "    un = message['map']['event_data.subjectusername'].strip().replace('\"','')\n",
    "    cl = message['map']['event_data.commandline'].strip().replace('\"','')\n",
    "    ppn = message['map']['event_data.parentprocessname'].strip().replace('\"','')\n",
    "    test_df['domain_name'].append(dn)\n",
    "    test_df['username'].append(un)\n",
    "    test_df['command_line'].append(cl)\n",
    "    test_df['parent_process_name'].append(ppn)\n",
    "    \n",
    "test_df = pd.DataFrame.from_dict(test_df)\n",
    "#print(test_df)\n",
    "#print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d464d48-6daa-480c-b766-409ad7539fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = apply(model, test_df, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d34f43-9d5c-4ab8-b23c-13d0dc78a930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions.describe()\n",
    "recon_mean = np.mean(predictions)\n",
    "recon_stddev = np.std(predictions)\n",
    "\n",
    "stats_threshold = recon_mean + 6*recon_stddev\n",
    "print(stats_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686e21a8-8df7-4968-89e4-3bd9470fd43b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "z = pd.DataFrame(predictions > stats_threshold)\n",
    "p_dropped = predictions[z.reconstruction_loss]\n",
    "\n",
    "for i in list(p_dropped.index.values):\n",
    "    print(test_df.iloc[i]['domain_name'] + ' ' + test_df.iloc[i]['username'] + ' ' + test_df.iloc[i]['command_line'] + ' ' + test_df.iloc[i]['parent_process_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20e392-c50d-41b9-9ac1-fe9eb65197ac",
   "metadata": {},
   "source": [
    "# 5. Tuning\n",
    "The final step is tuning the anomaly findings to your specifications. This involves a little bit of trial-and-error, but this can be adjusted using some of the following measures:\n",
    "* Adjusting the threshold for which anomalies are alerted\n",
    "* Adding known data to exclude from future anomaly alerting\n",
    "\n",
    "The below example excludes a known executable to make the anomaly findings cleaner. In production use, any exclusion needs to be as specific as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356fddd-ffc5-477a-acee-c87574fd317f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exclude_commandline = ['msedge.exe']\n",
    "\n",
    "for i in list(p_dropped.index.values):\n",
    "    found_exclude = False\n",
    "    for entry in exclude_commandline:\n",
    "        if entry in test_df.iloc[i]['command_line']:\n",
    "            found_exclude = True\n",
    "            break\n",
    "    if not found_exclude:\n",
    "        print(test_df.iloc[i]['domain_name'] + ' ' + test_df.iloc[i]['username'] + ' ' + test_df.iloc[i]['command_line'] + ' ' + test_df.iloc[i]['parent_process_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f3e8cc-437e-483b-9116-587ba9bd1e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('autoencodermodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869b2cc1-9c96-400e-b3b0-01d5ec8a2691",
   "metadata": {},
   "source": [
    "# 6. Deployment\n",
    "This anomaly finder will be deployed as a simple Python script and will need to be hosted on a server with adequate CPU and memory resources that can run Python scripts with Tensorflow and can connect to your SIEM. However, it can be customized to the client's specifications. Some deployment ideas include the following:\n",
    "\n",
    "* A daily/weekly email showing all anomaly findings\n",
    "* A running log file which can be ingested back into your SIEM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676c8a8-4f07-4452-958d-db4bc8fa2310",
   "metadata": {},
   "source": [
    "# 7. Maintenance\n",
    "Like any AI solution, the anomaly finder will need to be periodically retrained so that it stays up to date with any changes that occur in the environment. Some changes may include the following:\n",
    "\n",
    "* Schema changes in your SIEM\n",
    "* Software/hardware updates on the server that break the anomaly finder\n",
    "* Data drift\n",
    "\n",
    "QFunction can work with you to ensure that your anomaly finder stays operational."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f423a7-ce9d-4c98-8f6b-c72ac7011945",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167ee132-1691-4dd7-8e36-0d07337a063c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
